{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Verify Saved Model\n",
    "Load the previously saved model, features list, and metrics using joblib. Verify the model's current performance baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model and features...\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Further training model...\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load saved model and metadata\n",
    "model_path = \"/Users/chetan/Documents/GitHub/nj_transit/models/delay_predictor.joblib\"\n",
    "features_path = \"/Users/chetan/Documents/GitHub/nj_transit/models/features_list.joblib\"\n",
    "metrics_path = \"/Users/chetan/Documents/GitHub/nj_transit/models/metrics.joblib\"\n",
    "\n",
    "try:\n",
    "    # Load model and features\n",
    "    print(\"Loading saved model and features...\")\n",
    "    model = joblib.load(model_path)\n",
    "    features = joblib.load(features_path)\n",
    "    baseline_metrics = joblib.load(metrics_path)\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    data_path = '/Users/chetan/Documents/GitHub/nj_transit/data/data.csv'\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    print(\"Preprocessing data...\")\n",
    "    df['scheduled_time'] = pd.to_datetime(df['scheduled_time'], errors='coerce')\n",
    "    df['actual_time'] = pd.to_datetime(df['actual_time'], errors='coerce')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Drop invalid times\n",
    "    df = df.dropna(subset=['scheduled_time', 'actual_time'])\n",
    "\n",
    "    # Create features\n",
    "    df['hour_of_day'] = df['scheduled_time'].dt.hour\n",
    "    df['day_of_week'] = df['scheduled_time'].dt.dayofweek\n",
    "    df['month'] = df['scheduled_time'].dt.month\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['is_rush_hour'] = df['hour_of_day'].isin([7, 8, 9, 16, 17, 18, 19]).astype(int)\n",
    "\n",
    "    # Handle missing values\n",
    "    df['delay_minutes'] = df['delay_minutes'].fillna(0)\n",
    "    df['from_id'] = df['from_id'].fillna(-1)\n",
    "    df['to_id'] = df['to_id'].fillna(-1)\n",
    "\n",
    "    # Remove outliers\n",
    "    q1 = df['delay_minutes'].quantile(0.25)\n",
    "    q3 = df['delay_minutes'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    df = df[df['delay_minutes'].between(q1 - 1.5*iqr, q3 + 1.5*iqr)]\n",
    "\n",
    "    # One-hot encode categoricals\n",
    "    df = pd.get_dummies(df, columns=['line'], prefix='line')\n",
    "    df = pd.get_dummies(df, columns=['type'], prefix='type')\n",
    "    df = pd.get_dummies(df, columns=['status'], prefix='status')\n",
    "\n",
    "    # Ensure all expected features exist\n",
    "    for feature in features:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = 0\n",
    "\n",
    "    # Prepare features and target\n",
    "    X = df[features]\n",
    "    y = df['delay_minutes']\n",
    "\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(X),\n",
    "        columns=X.columns,\n",
    "        index=X.index\n",
    "    )\n",
    "\n",
    "    print(\"Further training model...\")\n",
    "    # Further train the model with new data\n",
    "    model.fit(X_imputed, y)\n",
    "\n",
    "    # Make predictions and evaluate\n",
    "    y_pred = model.predict(X_imputed)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"Previous MAE: {baseline_metrics['MAE']:.2f} minutes\")\n",
    "    print(f\"Updated MAE: {mae:.2f} minutes\")\n",
    "    print(f\"Previous RMSE: {baseline_metrics['RMSE']:.2f} minutes\")\n",
    "    print(f\"Updated RMSE: {rmse:.2f} minutes\")\n",
    "\n",
    " \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Save updated model and metrics\n",
    "print(\"\\nSaving updated model...\")\n",
    "joblib.dump(model, model_path)\n",
    "joblib.dump({'MAE': mae, 'RMSE': rmse}, metrics_path)\n",
    "print(\"Model updated successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
