{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import huggingface_hub and other necessary libraries for model handling and API interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Load Data\n",
    "print(\"Loading data...\")\n",
    "data_path = '/Users/chetan/Documents/GitHub/nj_transit/data/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Convert datetime columns\n",
    "df['scheduled_time'] = pd.to_datetime(df['scheduled_time'], errors='coerce')\n",
    "df['actual_time'] = pd.to_datetime(df['actual_time'], errors='coerce')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Drop rows where time conversion failed\n",
    "df = df.dropna(subset=['scheduled_time', 'actual_time'])\n",
    "\n",
    "# Create basic features\n",
    "df['hour_of_day'] = df['scheduled_time'].dt.hour\n",
    "df['day_of_week'] = df['scheduled_time'].dt.dayofweek\n",
    "df['month'] = df['scheduled_time'].dt.month\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "df['is_rush_hour'] = df['hour_of_day'].isin([7, 8, 9, 16, 17, 18, 19]).astype(int)\n",
    "\n",
    "# Handle missing values\n",
    "df['delay_minutes'] = df['delay_minutes'].fillna(0)\n",
    "df['from_id'] = df['from_id'].fillna(-1)\n",
    "df['to_id'] = df['to_id'].fillna(-1)\n",
    "\n",
    "# Remove outliers\n",
    "q1 = df['delay_minutes'].quantile(0.25)\n",
    "q3 = df['delay_minutes'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "df = df[df['delay_minutes'].between(q1 - 1.5*iqr, q3 + 1.5*iqr)]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "if 'line' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['line'], prefix='line')\n",
    "if 'type' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['type'], prefix='type')\n",
    "if 'status' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['status'], prefix='status')\n",
    "\n",
    "# Step 3: Prepare Features\n",
    "print(\"Preparing features...\")\n",
    "features = [\n",
    "    'hour_of_day', 'day_of_week', 'month', \n",
    "    'is_weekend', 'is_rush_hour',\n",
    "    'from_id', 'to_id'\n",
    "]\n",
    "\n",
    "# Add one-hot encoded columns\n",
    "features.extend([col for col in df.columns if col.startswith(('line_', 'type_', 'status_'))])\n",
    "\n",
    "# Verify all features exist\n",
    "features = [f for f in features if f in df.columns]\n",
    "print(f\"Using features: {features}\")\n",
    "\n",
    "X = df[features]\n",
    "y = df['delay_minutes']\n",
    "\n",
    "# Step 4: Split the data\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train model\n",
    "print(\"Training model...\")\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate model\n",
    "print(\"Evaluating model...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} minutes\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} minutes\")\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Simple prediction function\n",
    "def predict_delay(hour_of_day, day_of_week, from_id, to_id, month=None):\n",
    "    if month is None:\n",
    "        month = pd.Timestamp.now().month\n",
    "        \n",
    "    input_data = pd.DataFrame([{\n",
    "        'hour_of_day': hour_of_day,\n",
    "        'day_of_week': day_of_week,\n",
    "        'month': month,\n",
    "        'is_weekend': 1 if day_of_week in [5, 6] else 0,\n",
    "        'is_rush_hour': 1 if hour_of_day in [7, 8, 9, 16, 17, 18, 19] else 0,\n",
    "        'from_id': from_id,\n",
    "        'to_id': to_id\n",
    "    }])\n",
    "    \n",
    "    # Add dummy columns for categorical variables\n",
    "    for col in features:\n",
    "        if col not in input_data.columns:\n",
    "            input_data[col] = 0\n",
    "            \n",
    "    input_data = input_data[features]\n",
    "    return model.predict(input_data)[0]\n",
    "\n",
    "# Test prediction\n",
    "print(\"\\nTesting prediction...\")\n",
    "try:\n",
    "    example_prediction = predict_delay(8, 1, 105, 107)  # Example IDs\n",
    "    print(f\"Predicted delay: {example_prediction:.2f} minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in example prediction: {e}\")\n",
    "\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "import joblib\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model to File\n",
    "Save the trained model and necessary metadata (features list, performance metrics) to local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model to File\n",
    "\n",
    "# Save the trained model locally\n",
    "model_dir = '/Users/chetan/Documents/GitHub/nj_transit_data_ru_hack/models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, 'delay_prediction_model.joblib')\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Save features list and performance metrics\n",
    "features_path = os.path.join(model_dir, 'features_list.joblib')\n",
    "joblib.dump(features, features_path)\n",
    "\n",
    "metrics = {\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "}\n",
    "metrics_path = os.path.join(model_dir, 'metrics.joblib')\n",
    "joblib.dump(metrics, metrics_path)\n",
    "\n",
    "# Upload the model to Hugging Face\n",
    "api = HfApi()\n",
    "repo_url = api.create_repo(name=\"nj_transit_delay_prediction\", private=False)\n",
    "repo = Repository(local_dir=model_dir, clone_from=repo_url)\n",
    "\n",
    "# Add files to the repository and push\n",
    "repo.git_add()\n",
    "repo.git_commit(\"Add delay prediction model and metadata\")\n",
    "repo.git_push()\n",
    "\n",
    "# Load the model from Hugging Face for further predictions\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"delay_prediction_model.joblib\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "features_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"features_list.joblib\")\n",
    "features = joblib.load(features_path)\n",
    "\n",
    "metrics_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"metrics.joblib\")\n",
    "metrics = joblib.load(metrics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Load Data\n",
    "print(\"Loading data...\")\n",
    "data_path = '/Users/chetan/Documents/GitHub/nj_transit/data/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Convert datetime columns\n",
    "df['scheduled_time'] = pd.to_datetime(df['scheduled_time'], errors='coerce')\n",
    "df['actual_time'] = pd.to_datetime(df['actual_time'], errors='coerce')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Drop rows where time conversion failed\n",
    "df = df.dropna(subset=['scheduled_time', 'actual_time'])\n",
    "\n",
    "# Create basic features\n",
    "df['hour_of_day'] = df['scheduled_time'].dt.hour\n",
    "df['day_of_week'] = df['scheduled_time'].dt.dayofweek\n",
    "df['month'] = df['scheduled_time'].dt.month\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "df['is_rush_hour'] = df['hour_of_day'].isin([7, 8, 9, 16, 17, 18, 19]).astype(int)\n",
    "\n",
    "# Handle missing values\n",
    "df['delay_minutes'] = df['delay_minutes'].fillna(0)\n",
    "df['from_id'] = df['from_id'].fillna(-1)\n",
    "df['to_id'] = df['to_id'].fillna(-1)\n",
    "\n",
    "# Remove outliers\n",
    "q1 = df['delay_minutes'].quantile(0.25)\n",
    "q3 = df['delay_minutes'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "df = df[df['delay_minutes'].between(q1 - 1.5*iqr, q3 + 1.5*iqr)]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "if 'line' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['line'], prefix='line')\n",
    "if 'type' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['type'], prefix='type')\n",
    "if 'status' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['status'], prefix='status')\n",
    "\n",
    "# Step 3: Prepare Features\n",
    "print(\"Preparing features...\")\n",
    "features = [\n",
    "    'hour_of_day', 'day_of_week', 'month', \n",
    "    'is_weekend', 'is_rush_hour',\n",
    "    'from_id', 'to_id'\n",
    "]\n",
    "\n",
    "# Add one-hot encoded columns\n",
    "features.extend([col for col in df.columns if col.startswith(('line_', 'type_', 'status_'))])\n",
    "\n",
    "# Verify all features exist\n",
    "features = [f for f in features if f in df.columns]\n",
    "print(f\"Using features: {features}\")\n",
    "\n",
    "X = df[features]\n",
    "y = df['delay_minutes']\n",
    "\n",
    "# Step 4: Split the data\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train model\n",
    "print(\"Training model...\")\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate model\n",
    "print(\"Evaluating model...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} minutes\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} minutes\")\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Simple prediction function\n",
    "def predict_delay(hour_of_day, day_of_week, from_id, to_id, month=None):\n",
    "    if month is None:\n",
    "        month = pd.Timestamp.now().month\n",
    "        \n",
    "    input_data = pd.DataFrame([{\n",
    "        'hour_of_day': hour_of_day,\n",
    "        'day_of_week': day_of_week,\n",
    "        'month': month,\n",
    "        'is_weekend': 1 if day_of_week in [5, 6] else 0,\n",
    "        'is_rush_hour': 1 if hour_of_day in [7, 8, 9, 16, 17, 18, 19] else 0,\n",
    "        'from_id': from_id,\n",
    "        'to_id': to_id\n",
    "    }])\n",
    "    \n",
    "    # Add dummy columns for categorical variables\n",
    "    for col in features:\n",
    "        if col not in input_data.columns:\n",
    "            input_data[col] = 0\n",
    "            \n",
    "    input_data = input_data[features]\n",
    "    return model.predict(input_data)[0]\n",
    "\n",
    "# Test prediction\n",
    "print(\"\\nTesting prediction...\")\n",
    "try:\n",
    "    example_prediction = predict_delay(8, 1, 105, 107)  # Example IDs\n",
    "    print(f\"Predicted delay: {example_prediction:.2f} minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in example prediction: {e}\")\n",
    "\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Model to Hugging Face\n",
    "Create a Hugging Face repository and upload the model files using huggingface_hub API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Model to Hugging Face\n",
    "\n",
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "import joblib\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Save Model to File\n",
    "\n",
    "# Save the trained model locally\n",
    "model_dir = '/Users/chetan/Documents/GitHub/nj_transit_data_ru_hack/models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, 'delay_prediction_model.joblib')\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Save features list and performance metrics\n",
    "features_path = os.path.join(model_dir, 'features_list.joblib')\n",
    "joblib.dump(features, features_path)\n",
    "\n",
    "metrics = {\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "}\n",
    "metrics_path = os.path.join(model_dir, 'metrics.joblib')\n",
    "joblib.dump(metrics, metrics_path)\n",
    "\n",
    "# Upload the model to Hugging Face\n",
    "api = HfApi()\n",
    "repo_url = api.create_repo(name=\"nj_transit_delay_prediction\", private=False)\n",
    "repo = Repository(local_dir=model_dir, clone_from=repo_url)\n",
    "\n",
    "# Add files to the repository and push\n",
    "repo.git_add()\n",
    "repo.git_commit(\"Add delay prediction model and metadata\")\n",
    "repo.git_push()\n",
    "\n",
    "# Load the model from Hugging Face for further predictions\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"delay_prediction_model.joblib\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "features_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"features_list.joblib\")\n",
    "features = joblib.load(features_path)\n",
    "\n",
    "metrics_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"metrics.joblib\")\n",
    "metrics = joblib.load(metrics_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Use Model from Hugging Face\n",
    "Download the saved model from Hugging Face and prepare it for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and Use Model from Hugging Face\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import joblib\n",
    "\n",
    "# Load the model from Hugging Face for further predictions\n",
    "model_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"delay_prediction_model.joblib\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Load the features list from Hugging Face\n",
    "features_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"features_list.joblib\")\n",
    "features = joblib.load(features_path)\n",
    "\n",
    "# Load the performance metrics from Hugging Face\n",
    "metrics_path = hf_hub_download(repo_id=\"username/nj_transit_delay_prediction\", filename=\"metrics.joblib\")\n",
    "metrics = joblib.load(metrics_path)\n",
    "\n",
    "# Display the loaded metrics\n",
    "print(\"Loaded Model Performance Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {metrics['MAE']:.2f} minutes\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {metrics['RMSE']:.2f} minutes\")\n",
    "\n",
    "# Example prediction using the loaded model\n",
    "example_prediction = predict_delay(8, 1, 105, 107)  # Example IDs\n",
    "print(f\"Predicted delay: {example_prediction:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Predictions with Loaded Model\n",
    "Verify the loaded model works correctly by making test predictions and comparing with original results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Predictions with Loaded Model\n",
    "\n",
    "# Verify the loaded model works correctly by making test predictions and comparing with original results\n",
    "\n",
    "# Display the loaded metrics\n",
    "print(\"Loaded Model Performance Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {metrics['MAE']:.2f} minutes\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {metrics['RMSE']:.2f} minutes\")\n",
    "\n",
    "# Example prediction using the loaded model\n",
    "example_prediction = predict_delay(8, 1, 105, 107)  # Example IDs\n",
    "print(f\"Predicted delay: {example_prediction:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
